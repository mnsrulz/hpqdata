# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

name: publish parquet file

on:
  workflow_dispatch:
  
env:
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: 1
  DOTNET_NOLOGO: true
  RawDataDirectory: ${{ github.workspace}}/raw
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  dump-parquet:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        file-name:
          - LCA_Disclosure_Data_FY2021_Q1
          - LCA_Disclosure_Data_FY2021_Q2
          - LCA_Disclosure_Data_FY2021_Q3
          - LCA_Disclosure_Data_FY2021_Q4
          - LCA_Disclosure_Data_FY2022_Q1
          - LCA_Disclosure_Data_FY2022_Q2
          - LCA_Disclosure_Data_FY2022_Q3
          - LCA_Disclosure_Data_FY2022_Q4
          - LCA_Disclosure_Data_FY2023_Q1
    steps:
      - uses: actions/checkout@v3
      - name: Setup python sqlite-utils
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      - run: pip install -r requirements.txt
      - run: |
          import pandas
          df = pandas.read_excel('https://www.dol.gov/sites/dolgov/files/ETA/oflc/pdfs/${{ matrix.file-name }}.xlsx', 
            nrows= 99, 
            converters={
              'EMPLOYER_POSTAL_CODE':str,
              'EMPLOYER_NAME':str,
              'WORKSITE_POSTAL_CODE':str
            })
          df = df.loc[:, ['CASE_NUMBER', 'CASE_STATUS', 'JOB_TITLE', 'BEGIN_DATE', 'END_DATE', 'TOTAL_WORKER_POSITIONS', 'NEW_EMPLOYMENT', 'CONTINUED_EMPLOYMENT', 'EMPLOYER_NAME', 'WORKSITE_STATE', 'WORKSITE_POSTAL_CODE','EMPLOYER_CITY', 'EMPLOYER_STATE', 'EMPLOYER_POSTAL_CODE','WAGE_RATE_OF_PAY_FROM', 'WAGE_RATE_OF_PAY_TO', 'WAGE_UNIT_OF_PAY', 'PREVAILING_WAGE', 'PW_UNIT_OF_PAY']]
          df.to_parquet('${{ matrix.file-name }}.parquet')
        shell: python
          
      - name: Upload artifacts 
        uses: actions/upload-artifact@v3
        with:
          name: ${{ matrix.file-name }}
          if-no-files-found: error
          path: ${{ github.workspace}}/*.parquet
          retention-days: 1
  deploy-to-github:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    needs: dump-parquet
    if: success()
    steps:
      - name: Checkout üõéÔ∏è
        uses: actions/checkout@v3
        
      - name: Download artifacts üîß
        uses: actions/download-artifact@v3
        with:
          path: parquet_dumps
      - name: Create build directory
        run: |
          mkdir -p build/data
      - name: Setup python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      - run: pip install -r requirements.txt
      - run: |
          from pathlib import Path
          import pandas as pd

          data_dir = Path('parquet_dumps')
          full_df = pd.concat(
              pd.read_parquet(parquet_file)
              for parquet_file in data_dir.rglob('*.parquet')
          )
          full_df.to_parquet('build/data/db.parquet')
        shell: python
        
      - name: Deploy üöÄ
        uses: JamesIves/github-pages-deploy-action@v4
        with:
          folder: build # The folder the action should deploy.
          clean: true # Automatically remove deleted files from the deploy branch
